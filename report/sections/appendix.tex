\appendix
\section{Appendix}
\begin{table*}[h!]
\centering
\renewcommand{\arraystretch}{1.2} % Adjusts row height for better readability
\begin{tabular}{|l|l|p{6cm}|}
\hline
\textbf{Model} & \textbf{Parameter} & \textbf{Tuning Range} \\
\hline
\multirow{1}{*}{Ridge} & alpha & [0.001, 0.01, 0.1, 1, 10] \\
\hline
\multirow{1}{*}{Lasso} & alpha & [0.0001, 0.001, 0.01, 0.1] \\
\hline
\multirow{2}{*}{ElasticNet} & alpha & [0.001, 1, 100] \\
\cline{2-3}
 & l1\_ratio & [1.0, 0.0, 0.5] \\
\hline
\multirow{3}{*}{KNeighborsRegressor} & n\_neighbors & [1, 3, 5] \\
\cline{2-3}
 & weights & [uniform, distance] \\
\cline{2-3}
 & p & [1, 2] \\
\hline
\multirow{3}{*}{SVR} & kernel & [linear, rbf] \\
\cline{2-3}
 & C & [0.1, 1, 10, 100, 1000] \\
\cline{2-3}
 & gamma & [0.0001, 0.001, 0.01, 0.1, 1] \\
\hline
\multirow{4}{*}{RandomForestRegressor} & n\_estimators & [100, 300, 800] \\
\cline{2-3}
 & max\_depth & [5, 10, None] \\
\cline{2-3}
 & max\_features & [1.0, sqrt, log2] \\
\cline{2-3}
 & min\_samples\_leaf & [1, 2, 4] \\
\hline
\multirow{7}{*}{XGBRegressor} & learning\_rate & [0.05, 0.1] \\
\cline{2-3}
 & max\_depth & [3, 5] \\
\cline{2-3}
 & min\_child\_weight & [3, 5] \\
\cline{2-3}
 & subsample & [0.7] \\
\cline{2-3}
 & colsample\_bytree & [0.8, 1.0] \\
\cline{2-3}
 & gamma & [0] \\
\cline{2-3}
 & n\_estimators & [100, 200] \\
\hline
\multirow{5}{*}{XGBRFRegressor} & max\_depth & [3, 6] \\
\cline{2-3}
 & num\_parallel\_tree & [100, 200] \\
\cline{2-3}
 & subsample & [0.6, 0.8] \\
\cline{2-3}
 & colsample\_bynode & [0.5, 0.7] \\
\cline{2-3}
 & n\_estimators & [100] \\
\hline
\end{tabular}
\caption{Hyperparameter Tuning Ranges for Various Models}
\label{tab:hyperparameters}
\end{table*}