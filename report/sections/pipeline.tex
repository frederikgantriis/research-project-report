\section{Project structure}

As described in \autoref{sec:case}, \ap wants to predict cyclone blockages by predicting the difference in temperature between a sensor at top and bottom of a given cyclone. For this project, the lowest cyclone, also refereed to as the second step cyclone, was chosen as the main focus point due to the amount of blockages there have been within the last two years.

The project is structured in a data-centred pipeline. To achieve this, \textit{Data Version Control} (DVC) \footnote{\url{https://dvc.org/doc}} was used for both managing and versioning the data received from Aalborg Portland, as well as managing the testing and hyper-parameter tuning.

The pipeline consist of the following steps:

\begin{enumerate}
    \item \textbf{Data Preparation}: The data given is merged and have an initial cleaning. The goal of this step, is to prepare the data for visualisations and transformations in later steps.
    \item \textbf{Data analysis}: This steps has the sole purpose of analysing and visualising the raw data. This includes making a correlation analysis, generating descriptive statistics, and plotting the initial data.
    \item \textbf{Preprocessing}: Here, the data is prepared for training and testing of all the different models. This includes, filling missing values, standardisation and splitting the dataset into the sections train and test. 
    \item \textbf{Training}: In this step, the models are trained and validated. Each fold is measured with \textit{Root Mean Squared Error (RMSE)}.
    \item \textbf{Evaluation}: The last step in the pipeline, is concerned testing the models, following by visualisation and evaluation of the results.
\end{enumerate}

The structure of the pipeline enabled easy development and testing of different models. Consequently, DVC isolates all parameters into a single file along with an option to queue multiple experiments. As a results, hyper-parameter tuning was easy to structure and allowed experiments to be easily reproduce-able at any given point.
