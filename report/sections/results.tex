\section{Results}

All models explained in \autoref{sec:training}, apart from \xgbr and \xrf, were implemented using the \texttt{scikit-learn}\footnote{\url{https://scikit-learn.org/stable/}} library in the Python programming language. Both \xgbr and \xrf were implemented using the \textit{XGBoost}\footnote{\url{https://xgboost-clone.readthedocs.io/en/latest/}} library. Furthermore, all metrics used were also calculated using the mentioned \textit{scikit-learn} library. 

Looking at all the presented results, it becomes clear that \svr is missing from the visualisation. This is due to experimentation taking more time than initially planned, and all experiments were therefore removed. This pattern was both shown when running the given model on both CPU and GPU. This means, that while \svr might have provided good results, testing and experimentation were focused on hyper-parameter tuning other models with shorter completion-times.

\todo{Add visualisations of metrics comparisons to other models}
\todo{Describe the best performing models based on metrics}

\input{report/plots/maxerror}
\input{report/plots/rmse}
\input{report/plots/mae}
\input{report/plots/mape}

